{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RodrigoGuedesDP/IA/blob/main/maestria_mlp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# T칤tulo:\n",
        "Dise침o, Implementaci칩n y Evaluaci칩n de una Red Neuronal MLP para la Clasificaci칩n de Rostros\n",
        "\n",
        "----\n",
        "\n",
        "# Descripci칩n:\n",
        "En este hackathon, cada equipo desarrollar치n un modelo de red neuronal de tipo Perceptr칩n Multicapa (MLP) utilizando PyTorch para clasificar una base de datos de im치genes de rostros. La base de datos consta de 2,410 im치genes, cada imagen est치 representada como un vector de  dimensi칩n de 32256. Las im치genes corresponden a 38 personas diferentes, donde cada persona tiene m칰ltiples fotograf칤as. El objetivo principal es explorar diferentes configuraciones del modelo ajustando el n칰mero de neuronas en una capa oculta y utilizando distintas funciones de activaci칩n. A trav칠s de estas pruebas, los estudiantes analizar치n el impacto de los hiperpar치metros en el rendimiento del modelo, implementar치n modificaciones en el c칩digo base provisto y presentar치n una evaluaci칩n cuantitativa de los resultados.\n",
        "\n",
        "----\n",
        "\n",
        "# Objetivos:\n",
        "## General:\n",
        "\n",
        "Dise침ar, implementar y evaluar una red neuronal MLP en PyTorch para la clasificaci칩n de im치genes de rostros.\n",
        "## Espec칤ficos:\n",
        "- Convertir y preparar los datos de im치genes en un formato adecuado para el entrenamiento del modelo.\n",
        "- Implementar una red neuronal MLP con una sola capa oculta y explorar el impacto del n칰mero de neuronas en el rendimiento del modelo.\n",
        "- Experimentar con diferentes funciones de activaci칩n, como ReLU, Sigmoid y Tanh, para observar sus efectos en la clasificaci칩n.\n",
        "- Implementar y completar el c칩digo base provisto, asegurando que sea funcional y eficiente.\n",
        "- Entrenar y evaluar m칰ltiples configuraciones de la red neuronal utilizando m칠tricas como accuracy, recall, precision y F1 score.\n",
        "- Comparar los resultados de las distintas configuraciones y determinar cu치l ofrece el mejor desempe침o.\n",
        "- Presentar los resultados en tablas y gr치ficas, explicando las conclusiones obtenidas.\n",
        "\n",
        "## Base de Datos:\n",
        "\n",
        "Link: [Aqu칤](https://drive.google.com/file/d/1X8-AJiG0_qW08rx5l8u1Vs3cmx5W8ETj/view?usp=sharing)\n"
      ],
      "metadata": {
        "id": "1rNh3vemBkKF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Para aprender, debemos entrenar nuestra propia red neuronal. No dependas de herramientas como ChatGPT o sus variantes. Entrena tu cerebro, equiv칩cate, identifica los errores y aprende de ellos, tal como lo har칤a una red neuronal MLP gigante.**\n",
        "\n",
        "----\n",
        "\n",
        "Mucha suerte y divierntanse aprendiendo. 游땕游땕游땕"
      ],
      "metadata": {
        "id": "mwt3RMA6uZlb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Librer칤as Necesarias"
      ],
      "metadata": {
        "id": "tDtsNuCg7yfp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "9wBzi7Us7wfr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Cargando datos de Archivo\n",
        "\n",
        "La funci칩n load_data carga todas las im치genes de un archivo .m.\n",
        "No se preocupe por eso, se har치 de forma transparente para usted."
      ],
      "metadata": {
        "id": "IoHqpK2V73Oy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import scipy.io\n",
        "import seaborn as sns\n",
        "from google.colab import drive\n",
        "drive.mount('/content/allFaces.mat')\n",
        "path = '/content/allFaces.mat'\n",
        "def Load_data(file):\n",
        "  faces_m_format = scipy.io.loadmat(path)\n",
        "  faces = faces_m_format['faces']\n",
        "  m = int(faces_m_format['m'])\n",
        "  n = int(faces_m_format['n'])\n",
        "  nfaces = np.ndarray.flatten(faces_m_format['nfaces'])\n",
        "  y = np.zeros((faces.shape[1],))\n",
        "  j = 0\n",
        "  classes = list(range(len(nfaces)))\n",
        "  for i in nfaces:\n",
        "    y[j:j+i] = classes.pop(0)\n",
        "    j = j + i\n",
        "  print(\"Total dataset size:\")\n",
        "  print(f\"n_samples: {faces.shape[1]}\")\n",
        "  print(f\"n_features: {m*n}\")\n",
        "  print(f\"n_classes: {len(nfaces)}\")\n",
        "  return faces, y,m,n\n",
        "\n",
        "X,Y,m,n = Load_data('allFaces.mat')\n",
        "\n"
      ],
      "metadata": {
        "id": "SN9Xw2BO79mf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "outputId": "d4878ed1-576f-4052-b7f5-8bfe80bfaef6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Mountpoint must either be a directory or not exist",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4288762572.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/allFaces.mat'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mLoad_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0mfaces_m_format\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadmat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    101\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    199\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Mountpoint must not already contain files'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Mountpoint must either be a directory or not exist'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0mnormed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormpath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'/'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnormed\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdirname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnormed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Mountpoint must either be a directory or not exist"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Funciones Utilitarias.\n",
        "La funci칩n Plot_Face se ha implementado para que pueda ver una imagen de su base de datos."
      ],
      "metadata": {
        "id": "4P0LG7fw8VwG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def Plot_Face(image_vec, i,title):\n",
        "  fig1 = plt.figure(figsize=(10, 3))\n",
        "  image = image_vec.reshape((m,n))\n",
        "  img = plt.imshow(image.T)\n",
        "  img.set_cmap('gray')\n",
        "  plt.title(title  + str(i))\n",
        "  plt.axis('off')\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "number_image = 12\n",
        "image_vec = X.T[number_image]\n",
        "Plot_Face(image_vec,number_image,'face ')\n",
        "X.shape"
      ],
      "metadata": {
        "id": "lnHaQpSi8WHF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "28d72c01-4e67-4998-9a8b-3b556145bc38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'X' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-769845932.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mnumber_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m12\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mimage_vec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnumber_image\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mPlot_Face\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_vec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnumber_image\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'face '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'X' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Reducci칩n de la dimensionalidad\n",
        "\n",
        "Completa el c칩digo para que sea funcional y permita reducir los datos, asegurando que se conserve el 95% de la varianza explicada."
      ],
      "metadata": {
        "id": "Wq2KiqEM8nwJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "pca=PCA(?)\n",
        "X_pca= ?\n",
        "\n",
        "plot(X_pca.shape)"
      ],
      "metadata": {
        "id": "I2NYCk9y8mT1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Separaci칩n de datos en train y test.\n",
        "Complete el c칩digo usando la libreria train_test_split\n",
        "\n",
        "1.  Divide los datos en conjuntos de entrenamiento y prueba utilizando train_test_split con un 25% para prueba.\n",
        "2.  Recuerda que los datos a dividir son X_pca y Y.\n",
        "3. Convierte los datos a tensores para que PyTorch pueda procesarlos correctamente.\n",
        "4. Crear los dataloader para entrerar y testear el modelo. Se da un ejemplo.\n"
      ],
      "metadata": {
        "id": "8zbkcp9y9GiL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sbF82EGY4pJA"
      },
      "outputs": [],
      "source": [
        "# Escriba su c칩digo aqu칤 para separar la data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convierte tus datos a tensores.\n",
        "# A continuaci칩n, te doy un ejemplo para X_test y Y_test.\n",
        "\n",
        "x_test_t = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_test_t = torch.tensor(y_test, dtype=torch.long)\n"
      ],
      "metadata": {
        "id": "tXFgGkU349X5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear TensorDataset y DataLoader. Te pongo un ejemplo para el test\n",
        "dataset_test = TensorDataset(x_test_t, y_test_t)\n",
        "batch_size = 16\n",
        "data_loader_test = DataLoader(dataset_test, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "X_bALISo5Lyi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Modelo\n",
        "\n",
        "Crea tu modelo MLP utilizando una  capa. Puedes experimentar con el n칰mero de neuronas en esa capa y las funciones de activaci칩n."
      ],
      "metadata": {
        "id": "J6ywkrff-IHc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Crea aqu칤 tu modelo\n",
        "class Modelo_MLP(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, output_size):\n",
        "    super(Modelo_MLP, self).__init__()\n",
        "    # Escribe el c칩digo que falta"
      ],
      "metadata": {
        "id": "X52fIC4D5XL-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. Configuraci칩n de Par치metros\n",
        "Configura los par치metros de tu modelo"
      ],
      "metadata": {
        "id": "bjm4Itxa-mcH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Par치metros del modelo\n",
        "input_size = ?\n",
        "hidden_sizes = [?]\n",
        "output_size = ?\n",
        "epochs = ?\n",
        "\n",
        "model = Modelo_MLP(input_size, hidden_sizes, output_size)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n"
      ],
      "metadata": {
        "id": "63ClTUc85xpV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7. Entrenamiento.\n",
        "Completar el c칩digo que falta para que la funci칩n se ejecute correctamente."
      ],
      "metadata": {
        "id": "36bKHOYY-3pC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Funci칩n de entrenamiento\n",
        "def train(model, criterion, optimizer, data_loader, epochs):\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "        total_loss = 0.0\n",
        "        for x_batch, y_batch in data_loader:\n",
        "          # Completa para que funcione\n",
        "        print(f\"칄poca {epoch + 1}/{epochs}, P칠rdida promedio: {total_loss / len(data_loader)}\")"
      ],
      "metadata": {
        "id": "fx1PIq7k58YZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 8. Testing\n",
        "Completa el c칩digo necesario para evaluar tu modelo.\n",
        "Se solicita que ajustes algunos hiperpar치metros para crear al menos 3 modelos diferentes y mostrar sus resultados en una tabla."
      ],
      "metadata": {
        "id": "Q4O-MGqn_AkW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, data_loader):\n",
        "    model.eval()\n",
        "    y_pred = []\n",
        "    y_rea침 = []\n",
        "    with torch.no_grad():\n",
        "        for x_batch, y_batch in data_loader:\n",
        "            # completa para evaluar los datos de test\n",
        "\n",
        "\n",
        "\n",
        "    # M칠tricas\n",
        "    accuracy = accuracy_score(y_real, y_pred)\n",
        "    # Completa con las m칠tricas que se te piden.\n",
        "    # Precision, Recall y F1_Score.\n"
      ],
      "metadata": {
        "id": "d3f7RRJC6BDv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 9. Ejecutando y evaluando el modelo\n",
        "- Si el c칩digo anterior es correcto, el siguiente fragmento deber칤a ejecutarse sin problemas.\n",
        "- El entrenamiento del modelo puede tardar entre 5 y 10 minutos, por lo que se recomienda tener paciencia.\n",
        "- Sugerencia: cada miembro del equipo puede probar configuraciones diferentes del modelo y, posteriormente, reunir los resultados en una tabla 칰nica para evaluar cu치l ofrece el mejor desempe침o.\n"
      ],
      "metadata": {
        "id": "Maw6NN-t_yaj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train(model, criterion, optimizer, data_loader_train, epochs)\n",
        "evaluate(model, data_loader_test)"
      ],
      "metadata": {
        "id": "dzga3gJB_ysj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Configura tu red, con diferentes n칰mero de neuronas y cambia las funciones de activaci칩n y genera\n",
        "una tabla, con los siguientes datos\n",
        "\n",
        "Esta es s칩lo una tabla de ejemplo:\n",
        "\n",
        "----\n",
        "| Neuronas Hidden | Tipo de Funci칩n de Activaci칩n | N칰mero de 칄pocas | Accuracy | Recall | Precision | F1_Score |\n",
        "|------------------|-------------------------------|------------------|----------|--------|-----------|----------|\n",
        "| 64, 32          | ReLU                          | 10               | 0.85     | 0.84   | 0.86      | 0.85     |\n",
        "| 128, 64         | Tanh                          | 20               | 0.89     | 0.88   | 0.90      | 0.89     |\n",
        "| 256, 128        | Sigmoid                       | 15               | 0.83     | 0.82   | 0.84      | 0.83     |\n",
        "| 512, 256        | ReLU                          | 30               | 0.91     | 0.90   | 0.92      | 0.91     |\n",
        "\n",
        "-----"
      ],
      "metadata": {
        "id": "V-MQbF5F7l0k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Q1oMmJKW7SGU"
      }
    }
  ]
}