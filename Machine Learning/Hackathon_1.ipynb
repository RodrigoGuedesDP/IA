{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RodrigoGuedesDP/IA/blob/main/Machine%20Learning/Hackathon_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hackathon 1: Regression\n",
        "\n",
        "### Participantes: (Colocar el % de participación)\n",
        "- 1 %\n",
        "- 2.%\n",
        "- 3 %\n",
        "- 4.%\n",
        "----\n",
        "\n",
        "- Hora Inicio: 10:00\n",
        "- Hora Fin   : 12:30\n",
        "\n",
        "-----\n",
        "\n",
        "##**Título del Problema:**  \n",
        "**\"Hackathon de Predicción de Ventas: Regresión No Lineal Polinómica con Regularización\"**\n",
        "\n",
        "---\n",
        "\n",
        "## **Contexto:**  \n",
        "En el dinámico entorno minorista, la capacidad de predecir con precisión las ventas mensuales es crucial para la planificación estratégica, la gestión de inventarios y la optimización de recursos. Una cadena de tiendas minoristas peruanas busca mejorar su toma de decisiones mediante la implementación de modelos predictivos avanzados que consideren tanto factores internos como externos que influyen en sus ventas.\n",
        "\n",
        "Para abordar este desafío, se han recolectado diversas variables que abarcan aspectos de marketing, operacionales y económicos. Dado que las relaciones entre estas variables y las ventas pueden ser complejas y no lineales, es fundamental utilizar técnicas de regresión que capturen estas dinámicas, al mismo tiempo que se evite el sobreajuste mediante métodos de regularización.\n",
        "\n",
        "---\n",
        "\n",
        "## **Objetivos del Problema:**  \n",
        "\n",
        "1. **Preprocesamiento y Exploración de Datos:**\n",
        "   - **Carga y Preparación de Datos:** Importar los conjuntos de datos proporcionados (`train_data.csv` con 10,000 observaciones y `val_data.csv` con 1,000 observaciones).\n",
        "   - **Análisis Exploratorio de Datos (EDA):** Realizar análisis estadísticos y visuales para comprender la distribución de las variables, detectar valores atípicos y explorar relaciones potenciales entre las variables predictoras y la variable objetivo \"Ventas\".\n",
        "\n",
        "2. **Ingeniería de Características:**\n",
        "   - **Generación de Características Polinómicas:** Utilizar `PolynomialFeatures` de scikit-learn para crear combinaciones de segundo grado de las variables predictoras, capturando así interacciones y relaciones no lineales.\n",
        "   - **Escalado de Datos:** Aplicar técnicas de escalado (como `StandardScaler`) para normalizar las variables y mejorar la estabilidad numérica de los modelos.\n",
        "\n",
        "3. **Desarrollo y Entrenamiento de Modelos:**\n",
        "   - **Modelos de Regresión Lineal y Polinómica:** Implementar modelos de regresión lineal simples y polinómica para establecer una línea base de desempeño.\n",
        "   - **Aplicación de Regularización:**\n",
        "     - **Regresión Lasso (L1):** Implementar regresión con regularización L1 para realizar selección de variables, identificando así las características más relevantes.\n",
        "     - **Regresión Ridge (L2):** Implementar regresión con regularización L2 para controlar la magnitud de los coeficientes y evitar el sobreajuste.\n",
        "   - **Entrenamiento de Modelos:** Ajustar los modelos utilizando el conjunto de entrenamiento, optimizando hiperparámetros como el grado polinómico y el parámetro de regularización (alpha).\n",
        "\n",
        "4. **Evaluación y Comparación de Modelos:**\n",
        "   - **Métricas de Desempeño:** Calcular métricas como **MSE (Mean Squared Error)**, **RMSE (Root Mean Squared Error)**, **R** y **R²** tanto en los conjuntos de entrenamiento como de validación.\n",
        "   - **Comparación de Regularizaciones:** Analizar cómo la regularización L1 y L2 afectan el desempeño del modelo, la selección de características y la capacidad de generalización.\n",
        "   - **Visualización de Resultados:** Crear tablas que muestren las métricas de desempeño de cada modelo, facilitando la comparación y selección del mejor enfoque.\n",
        "\n",
        "5. **Interpretación de Resultados y Conclusiones:**\n",
        "   - **Identificación de Variables Clave:** Determinar cuáles son las variables predictoras más importantes según los modelos entrenados, especialmente observando los coeficientes en modelos Lasso.\n",
        "   - **Impacto de la Regularización:** Evaluar cómo la regularización contribuye a mejorar el modelo y prevenir el sobreajuste.\n",
        "   - **Recomendaciones Estratégicas:** Proporcionar insights basados en los resultados obtenidos que puedan ayudar a la cadena de tiendas a optimizar sus estrategias de marketing, operaciones y gestión de recursos para maximizar las ventas.\n",
        "\n",
        "---\n",
        "\n",
        "## **Conjuntos de Datos Proporcionados:**\n",
        "\n",
        "[Donwload Trainin Data Set](https://drive.google.com/file/d/1-7ZT-MsA8zl1o_LquqVdJvb4e6A5297N/view?usp=sharing)\n",
        "\n",
        "[Donwload Validation Data Set](https://drive.google.com/file/d/1-70ISm2gOf-KxvP8IFjM0DfoyF6E3G4z/view?usp=sharing)\n",
        "\n",
        "\n",
        "\n",
        "Base de Datos\n",
        "\n",
        "- **train_data.csv:** Contiene 10,000 observaciones para el entrenamiento del modelo.\n",
        "- **val_data.csv:** Contiene 1,000 observaciones para la validación y evaluación del modelo.\n",
        "\n",
        "**Variables Predictoras:**\n",
        "\n",
        "1. **Gasto_Publicidad_Online:** Inversión mensual en publicidad digital (en miles de soles).\n",
        "2. **Num_Empleados:** Número de empleados promedio en la tienda durante el mes.\n",
        "3. **Tamaño_Tienda:** Superficie de la tienda en metros cuadrados.\n",
        "4. **Indice_Competencia:** Métrica entre 0 y 1 que indica el nivel de competencia en la zona (0 = baja competencia, 1 = alta competencia).\n",
        "5. **Nivel_Descuento:** Porcentaje promedio de descuento aplicado en las promociones mensuales.\n",
        "6. **Satisfaccion_Clientes:** Puntuación promedio de reseñas en línea (1 a 5).\n",
        "7. **Estacionalidad:** Índice entre 0 y 1 que refleja si se está en temporada alta (cercana a 1) o baja (cercana a 0).\n",
        "8. **Indice_Economico_Local:** Métrica (0.5 a 1.5) que indica la situación económica local (PIB per cápita relativo).\n",
        "9. **Fidelidad_Clientes:** Porcentaje de clientes que regresan al menos una vez al mes.\n",
        "10. **Gasto_Publicidad_Tradicional:** Inversión mensual en publicidad offline (TV, radio, prensa) (en miles de soles).\n",
        "\n",
        "**Variable Objetivo:**\n",
        "\n",
        "- **Ventas:** Ventas mensuales promedio de la tienda (en miles de soles).\n",
        "\n",
        "---\n",
        "\n",
        "**Preguntas a Responder al Final del Hackathon:**\n",
        "\n",
        "1. **Desempeño del Modelo:**\n",
        "   - ¿Cuál es el **MSE** y **R²** obtenidos por cada modelo (sin regularización, Lasso, Ridge) en los conjuntos de entrenamiento y validación?\n",
        "   - ¿Qué modelo mostró el mejor rendimiento en términos de precisión y capacidad de generalización?\n",
        "\n",
        "2. **Impacto de la Regularización:**\n",
        "   - ¿Cuántos coeficientes fueron reducidos a cero en el modelo Lasso?\n",
        "   - ¿Cómo afectó la regularización L1 y L2 al desempeño del modelo en comparación con el modelo sin regularización?\n",
        "\n",
        "3. **Importancia de las Variables:**\n",
        "   - ¿Cuáles son las variables predictoras más relevantes según los modelos Lasso y Ridge?\n",
        "   - ¿Qué diferencias observan en la selección de variables entre Lasso y Ridge?\n",
        "\n",
        "4. **Análisis de Sobreajuste:**\n",
        "   - ¿Existe una diferencia significativa entre el desempeño en entrenamiento y validación que indique sobreajuste? ¿Cómo lo mitigaron?\n",
        "   \n",
        "5. **Mejoras y Aprendizajes:**\n",
        "   - ¿Qué técnicas adicionales implementarían para mejorar el rendimiento del modelo?\n",
        "   - ¿Qué aprendieron sobre la importancia de la generación de características polinómicas y la aplicación de regularización en problemas de regresión no lineal?\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "pXJClOJxyAER"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nM1bN4EGvyLe",
        "outputId": "62437a27-ffba-4c38-d7dd-b66310731ce3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/drive/MyDrive/UTEC/CURSOS/2024.2/MAESTRIA CURSOS/Machine Learning/Base de datos/hack_train_data.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-826a064a8607>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;34m\"/content/drive/MyDrive/UTEC/CURSOS/2024.2/MAESTRIA CURSOS/Machine Learning/Base de datos/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# 1. Cargar los datos desde los archivos CSV\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mtrain_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"hack_train_data.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mval_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m \u001b[0;34m+\u001b[0m  \u001b[0;34m\"hack_val_data.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/UTEC/CURSOS/2024.2/MAESTRIA CURSOS/Machine Learning/Base de datos/hack_train_data.csv'"
          ]
        }
      ],
      "source": [
        "# Use estas librerias para resolver el problema\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
        "from sklearn.linear_model import Ridge, Lasso\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "path =\"/content/drive/MyDrive/UTEC/CURSOS/2024.2/MAESTRIA CURSOS/Machine Learning/Base de datos/\"\n",
        "# 1. Cargar los datos desde los archivos CSV\n",
        "train_data = pd.read_csv(path + \"hack_train_data.csv\")\n",
        "val_data = pd.read_csv(path +  \"hack_val_data.csv\")\n",
        "\n",
        "# 2. Separar características y etiqueta\n",
        "X_train = train_data.drop('Ventas', axis=1)\n",
        "y_train = train_data['Ventas']\n",
        "\n",
        "X_val = val_data.drop('Ventas', axis=1)\n",
        "y_val = val_data['Ventas']\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Documentacion de la libreria necesaria para realizar el hackthon.hackthon.\n",
        "\n",
        "Gracias por señalarlo. Aquí tienes una tabla actualizada, incluyendo la regularización lineal:\n",
        "\n",
        "| **Librería / Clase / Función**         | **Enlace a la documentación**                                                                                          |\n",
        "|----------------------------------------|------------------------------------------------------------------------------------------------------------------------|\n",
        "| `StandardScaler`                       | [Documentación de StandardScaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html) |\n",
        "| `PolynomialFeatures`                   | [Documentación de PolynomialFeatures](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PolynomialFeatures.html) |\n",
        "| `Ridge` (Regresión Lineal con L2)      | [Documentación de Ridge](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html)             |\n",
        "| `Lasso` (Regresión Lineal con L1)      | [Documentación de Lasso](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html)             |\n",
        "| `LinearRegression` (Regresión Lineal)  | [Documentación de LinearRegression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html) |\n",
        "| `mean_squared_error`                   | [Documentación de mean_squared_error](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_squared_error.html) |\n",
        "| `r2_score`                             | [Documentación de r2_score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.r2_score.html)           |\n",
        "| `matplotlib.pyplot`                    | [Documentación de matplotlib.pyplot](https://matplotlib.org/stable/api/pyplot_summary.html)                             |\n",
        "\n"
      ],
      "metadata": {
        "id": "DFtZGBYD5HSh"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZmGZGwmU5GNP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "WjpLy2pGx9pO"
      }
    }
  ]
}